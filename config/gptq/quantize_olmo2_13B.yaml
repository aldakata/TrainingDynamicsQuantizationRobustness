awq: false
batch_size: 1
block_name_to_quantize: model.layers
block_size: 2048
bnb: false
dataset_path: /fast/atatjer/hf_fast/datasets/refinedweb/
debug: false
device: cuda
do_fuse: false
eval: true
fuse_max_seq_len: 512
gptq: true
gptq_dataset: c4
group_size: 128
calibration_batch_size: 16
gptq_model_seqlength: 512
hf_hub_name: scalinglawsquantized
model_file_patterns: '*.safetensors,*config.json'
model_quantized_dir: /fast/atatjer/scalinglawsquantization/lawa/
num_workers: 4
push_to_hf_hub: false
q_bits:
- 4
- 3
quantize: true
max_model_len: 4096

repo_origin:
- allenai/OLMo-2-1124-13B
revision:
- 'stage1-step38000-tokens319B'
- 'stage1-step78000-tokens655B'
- 'stage1-step97000-tokens814B'
- 'stage1-step108500-tokens911B'
- 'stage1-step129000-tokens1083B'
- 'stage1-step163000-tokens1368B'
- 'stage1-step183000-tokens1536B'
- 'stage1-step223000-tokens1871B'
- 'stage1-step243000-tokens2039B'
- 'stage1-step283000-tokens2374B'
- 'stage1-step320700-tokens2691B'
- 'stage1-step359000-tokens3012B'
- 'stage1-step396000-tokens3322B'
- 'stage1-step435000-tokens3650B'
- 'stage1-step474000-tokens3977B'
- 'stage1-step512000-tokens4295B'
- 'stage1-step552000-tokens4631B'
- 'stage1-step592000-tokens4967B'
- 'stage1-step594000-tokens4983B'
- 'stage1-step596057-tokens5001B'
- 'stage2-ingredient1-step1000-tokens9B'
- 'stage2-ingredient1-step11000-tokens93B'
- 'stage2-ingredient1-step11931-tokens100B'
- 'stage2-ingredient2-step2000-tokens17B'
- 'stage2-ingredient2-step11931-tokens100B'
- 'stage2-ingredient3-step1000-tokens9B'
- 'stage2-ingredient3-step11931-tokens100B'
- 'stage2-ingredient4-step1000-tokens9B'
- 'stage2-ingredient4-step11000-tokens93B'
- 'stage2-ingredient4-step21000-tokens177B'
- 'stage2-ingredient4-step31000-tokens261B'
- 'stage2-ingredient4-step35773-tokens300B'
- 'main'
save_quantized_model: True
tokenizer_name:
- allenai/OLMo-2-1124-13B
use_quant_cache: True
wandb_dir: /fast/atatjer/wandb/scalinglawsquantization
wandb_project: trainingdynamicsquantization
wandb_run_name: OLMo-2-1124-13B