awq: false
batch_size: 1
block_name_to_quantize: model.layers
block_size: 2048
bnb: false
dataset_path: /fast/atatjer/hf_fast/datasets/refinedweb/
debug: false
device: cuda
do_fuse: false
eval: true
fuse_max_seq_len: 512
gptq: true
gptq_dataset: c4
group_size: 128
calibration_batch_size: 16
gptq_model_seqlength: 512
hf_hub_name: scalinglawsquantized
model_file_patterns: '*.safetensors,*config.json'
model_quantized_dir: /fast/atatjer/scalinglawsquantization/lawa
num_workers: 4
push_to_hf_hub: false
q_bits:
- 3
- 4

quantize: true
max_model_len: 4096

repo_origin:
- allenai/OLMo-2-1124-7B
revision: 
-  'stage1-step35000-tokens147B'
-  'stage1-step55000-tokens231B'
-  'stage1-step75000-tokens315B'
-  'stage1-step95000-tokens399B'
-  'stage1-step116000-tokens487B'
-  'stage1-step136000-tokens571B'
-  'stage1-step156000-tokens655B'
-  'stage1-step177000-tokens743B'
-  'stage1-step197000-tokens827B'
-  'stage1-step217000-tokens911B'
-  'stage1-step237000-tokens995B'
-  'stage1-step257000-tokens1078B'
-  'stage1-step277000-tokens1162B'
-  'stage1-step297000-tokens1246B'
-  'stage1-step318000-tokens1334B'
-  'stage1-step338000-tokens1418B'
-  'stage1-step358000-tokens1502B'
-  'stage1-step378000-tokens1586B'
-  'stage1-step398000-tokens1670B'
-  'stage1-step418000-tokens1754B'
-  'stage1-step438000-tokens1838B'
-  'stage1-step458000-tokens1921B'
-  'stage1-step498000-tokens2089B'
-  'stage1-step518000-tokens2173B'
-  'stage1-step539000-tokens2261B'
-  'stage1-step559000-tokens2345B'
-  'stage1-step579000-tokens2429B'
-  'stage1-step599000-tokens2513B'
-  'stage1-step620000-tokens2601B'
-  'stage1-step641000-tokens2689B'
-  'stage1-step661000-tokens2773B'
-  'stage1-step682000-tokens2861B'
-  'stage1-step702000-tokens2945B'
-  'stage1-step722000-tokens3029B'
-  'stage1-step742000-tokens3113B'
-  'stage1-step762000-tokens3197B'
-  'stage1-step782000-tokens3280B'
-  'stage1-step802000-tokens3364B'
-  'stage1-step822000-tokens3448B'
-  'stage1-step842000-tokens3532B'
-  'stage1-step862000-tokens3616B'
-  'stage1-step882000-tokens3700B'
-  'stage1-step902000-tokens3784B'
-  'stage1-step922000-tokens3868B'
-  'stage1-step928646-tokens3896B'
-  'stage2-ingredient1-step1000-tokens5B'
-  'stage2-ingredient1-step11000-tokens47B'
-  'stage2-ingredient1-step11931-tokens50B'
-  'stage2-ingredient2-step1000-tokens5B'
-  'stage2-ingredient2-step11000-tokens47B'
-  'stage2-ingredient2-step11931-tokens50B'
-  'stage2-ingredient3-step1000-tokens5B'
-  'stage2-ingredient3-step11000-tokens47B'
-  'stage2-ingredient3-step11931-tokens50B'
-  'main'
save_quantized_model: True
tokenizer_name:
- allenai/OLMo-2-1124-7B
use_quant_cache: False
wandb_dir: /fast/atatjer/wandb/scalinglawsquantization
wandb_project: trainingdynamicsquantization
wandb_run_name: OLMo-2-1124-7B